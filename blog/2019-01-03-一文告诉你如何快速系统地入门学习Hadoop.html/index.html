<!DOCTYPE html>



  


<html class="theme-next gemini use-motion" lang="zh-Hans">
<head>
  <meta charset="UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=edge" />
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"/>
<meta name="theme-color" content="#222">









<meta http-equiv="Cache-Control" content="no-transform" />
<meta http-equiv="Cache-Control" content="no-siteapp" />
















  
  
  <link href="/lib/fancybox/source/jquery.fancybox.css?v=2.1.5" rel="stylesheet" type="text/css" />







<link href="/lib/font-awesome/css/font-awesome.min.css?v=4.6.2" rel="stylesheet" type="text/css" />

<link href="/css/main.css?v=5.1.4" rel="stylesheet" type="text/css" />


  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png?v=5.1.4">


  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png?v=5.1.4">


  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png?v=5.1.4">


  <link rel="mask-icon" href="/images/logo.svg?v=5.1.4" color="#222">





  <meta name="keywords" content="Hadoop," />










<meta name="description" content="Hadoop概述Hadoop是分布式系统基础架构，其核心包括HDFS（分布式文件系统）、MapReduce（分布式计算系统）、YARN（分布式资源调度和管理系统） Google三驾马车 GFS发展成HDFS Google BigTable发展成HBase Google MapReduce发展成MapReduce  Google大数据三篇著名论文中文版 Hadoop生态系统 蓝色部分，是Hadoop">
<meta name="keywords" content="Hadoop">
<meta property="og:type" content="article">
<meta property="og:title" content="一文告诉你如何快速系统地入门学习Hadoop">
<meta property="og:url" content="http://yoursite.com/blog/2019-01-03-一文告诉你如何快速系统地入门学习Hadoop.html/index.html">
<meta property="og:site_name" content="Josonlee&#39;s Blog">
<meta property="og:description" content="Hadoop概述Hadoop是分布式系统基础架构，其核心包括HDFS（分布式文件系统）、MapReduce（分布式计算系统）、YARN（分布式资源调度和管理系统） Google三驾马车 GFS发展成HDFS Google BigTable发展成HBase Google MapReduce发展成MapReduce  Google大数据三篇著名论文中文版 Hadoop生态系统 蓝色部分，是Hadoop">
<meta property="og:locale" content="zh-Hans">
<meta property="og:image" content="https://pic2.zhimg.com/80/v2-c07c85dfa597fe9b6a1c63b24948323d_hd.png">
<meta property="og:image" content="http://yoursite.com/MarkDown_images/大数据/writable.png">
<meta property="og:image" content="https://s1.ax1x.com/2018/12/24/FcpYGT.png">
<meta property="og:image" content="https://s1.ax1x.com/2018/12/24/Fcp8I0.jpg">
<meta property="og:image" content="https://s1.ax1x.com/2018/12/24/FcptRU.png">
<meta property="og:updated_time" content="2019-01-03T01:28:23.789Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="一文告诉你如何快速系统地入门学习Hadoop">
<meta name="twitter:description" content="Hadoop概述Hadoop是分布式系统基础架构，其核心包括HDFS（分布式文件系统）、MapReduce（分布式计算系统）、YARN（分布式资源调度和管理系统） Google三驾马车 GFS发展成HDFS Google BigTable发展成HBase Google MapReduce发展成MapReduce  Google大数据三篇著名论文中文版 Hadoop生态系统 蓝色部分，是Hadoop">
<meta name="twitter:image" content="https://pic2.zhimg.com/80/v2-c07c85dfa597fe9b6a1c63b24948323d_hd.png">



<script type="text/javascript" id="hexo.configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    root: '/',
    scheme: 'Gemini',
    version: '5.1.4',
    sidebar: {"position":"left","display":"post","offset":12,"b2t":false,"scrollpercent":false,"onmobile":false},
    fancybox: true,
    tabs: true,
    motion: {"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},
    duoshuo: {
      userId: '0',
      author: '博主'
    },
    algolia: {
      applicationID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    }
  };
</script>



  <link rel="canonical" href="http://yoursite.com/blog/2019-01-03-一文告诉你如何快速系统地入门学习Hadoop.html/"/>





  <title>一文告诉你如何快速系统地入门学习Hadoop | Josonlee's Blog</title>
  








</head>

<body itemscope itemtype="http://schema.org/WebPage" lang="zh-Hans">

  
  
    
  

  <div class="container sidebar-position-left page-post-detail">
    <div class="headband"></div>

    <header id="header" class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-wrapper">
  <div class="site-meta ">
    

    <div class="custom-logo-site-title">
      <a href="/"  class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">Josonlee's Blog</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
      
        <p class="site-subtitle">一点一滴 始于足下</p>
      
  </div>

  <div class="site-nav-toggle">
    <button>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
    </button>
  </div>
</div>

<nav class="site-nav">
  

  
    <ul id="menu" class="menu">
      
        
        <li class="menu-item menu-item-home">
          <a href="/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-home"></i> <br />
            
            首页
          </a>
        </li>
      
        
        <li class="menu-item menu-item-about">
          <a href="/about/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-user"></i> <br />
            
            关于
          </a>
        </li>
      
        
        <li class="menu-item menu-item-tags">
          <a href="/tags/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-tags"></i> <br />
            
            标签
          </a>
        </li>
      
        
        <li class="menu-item menu-item-categories">
          <a href="/categories/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-th"></i> <br />
            
            分类
          </a>
        </li>
      
        
        <li class="menu-item menu-item-archives">
          <a href="/archives/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-archive"></i> <br />
            
            归档
          </a>
        </li>
      
        
        <li class="menu-item menu-item-guestbook">
          <a href="/guestbook" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-question-circle"></i> <br />
            
            给我留言
          </a>
        </li>
      
        
        <li class="menu-item menu-item-book">
          <a href="/book/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-book"></i> <br />
            
            读书
          </a>
        </li>
      

      
    </ul>
  

  
</nav>



 </div>
    </header>

    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          <div id="content" class="content">
            

  <div id="posts" class="posts-expand">
    

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/blog/2019-01-03-一文告诉你如何快速系统地入门学习Hadoop.html/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Joson lee">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/logo.png">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Josonlee's Blog">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">一文告诉你如何快速系统地入门学习Hadoop</h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2019-01-03T09:17:20+08:00">
                2019-01-03
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/大数据/" itemprop="url" rel="index">
                    <span itemprop="name">大数据</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

             <span class="post-meta-divider">|</span>   <span id="busuanzi_value_page_pv"></span>次阅读 
          
          
            <div class="post-wordcount">
              
                
                <span class="post-meta-item-icon">
                  <i class="fa fa-file-word-o"></i>
                </span>
                
                  <span class="post-meta-item-text">字数统计&#58;</span>
                
                <span title="字数统计">
                  
                </span>
              

              

              
            </div>
          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        <h2 id="Hadoop概述"><a href="#Hadoop概述" class="headerlink" title="Hadoop概述"></a>Hadoop概述</h2><p>Hadoop是分布式系统基础架构，其核心包括HDFS（分布式文件系统）、MapReduce（分布式计算系统）、YARN（分布式资源调度和管理系统）</p>
<h3 id="Google三驾马车"><a href="#Google三驾马车" class="headerlink" title="Google三驾马车"></a>Google三驾马车</h3><ul>
<li>GFS发展成HDFS</li>
<li>Google BigTable发展成HBase</li>
<li>Google MapReduce发展成MapReduce</li>
</ul>
<p><a href="https://blog.csdn.net/robert198837/article/details/14103441?utm_source=blogxgwz0" target="_blank" rel="noopener">Google大数据三篇著名论文中文版</a></p>
<h2 id="Hadoop生态系统"><a href="#Hadoop生态系统" class="headerlink" title="Hadoop生态系统"></a>Hadoop生态系统</h2><p><img src="https://pic2.zhimg.com/80/v2-c07c85dfa597fe9b6a1c63b24948323d_hd.png" alt=""></p>
<p>蓝色部分，是Hadoop生态系统组件，黄色部分是Spark生态组件。二者并非互斥，像MR和Spark是共生关系，Spark提供了基于内存的实时计算，Hadoop提供了Spark没有的分布式文件系统，但Spark不一定就依赖HDFS，可以借助AWS的S3</p>
<p>HSQL未来可能会被Spark SQL替代，现在很多企业都是HIVE SQL和Spark SQL两种工具共存，当Spark SQL逐步成熟的时候，就有可能替换HSQL；</p>
<p>MapReduce绝对会被Spark替换，趋势是这样，Spark发展很快</p>
<p>Hadoop中的算法库Mahout正被Spark中的算法库MLib所替代，我觉得可以在Spark学习中侧重选择Spark Mlib学习</p>
<p>但是Hadoop也非常重要，我感觉绝对不会被Spark取代。为什么呢？就是因为它的HDFS分布式文件系统<br><a id="more"></a></p>
<h2 id="Hadoop先修准备Linux-shell学习"><a href="#Hadoop先修准备Linux-shell学习" class="headerlink" title="Hadoop先修准备Linux shell学习"></a>Hadoop先修准备Linux shell学习</h2><h2 id="掌握Hadoop集群搭建"><a href="#掌握Hadoop集群搭建" class="headerlink" title="掌握Hadoop集群搭建"></a>掌握Hadoop集群搭建</h2><p>见 <a href="https://blog.csdn.net/lzw2016/article/details/84197986" target="_blank" rel="noopener">大数据之Hadoop学习（环境配置）——Hadoop伪分布式集群搭建</a></p>
<h3 id="有几点需要注意"><a href="#有几点需要注意" class="headerlink" title="有几点需要注意"></a>有几点需要注意</h3><ul>
<li>安装配置JDK环境</li>
</ul>
<p>编辑全局环境变量文件<code>/etc/profile</code>，最后要<code>source /etc/profile</code>生效</p>
<ul>
<li>解压<code>.tar.gz</code>文件</li>
</ul>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"># tar -zxvf hadoop-2.6.0-cdh5.12.1.tar.gz -C /home/hadoop</span><br></pre></td></tr></table></figure>
<ul>
<li>解压<code>.tar</code>文件</li>
</ul>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"># tar -xvf XXX.tar -C [解压到哪个目录]</span><br></pre></td></tr></table></figure>
<blockquote>
<p>-C &lt;目录&gt;：这个选项用在解压缩，若要在特定目录解压缩，可以使用这个选项</p>
<p>-z或–gzip或–ungzip：通过gzip指令处理备份文件</p>
<p>-x或–extract或–get：从备份文件中还原文件</p>
<p>-v或–verbose：显示指令执行过程</p>
<p>-f&lt;备份文件&gt;或–file=&lt;备份文件&gt;：指定备份文件</p>
</blockquote>
<ul>
<li>在用户环境变量文件(<code>/home/hadoop/.bash_profile</code>)中配置Hadoop相关环境变量</li>
</ul>
<p>全局环境变量文件<code>/etc/profile</code>也可以，针对HADOOP_HOME, HADOOP_LOG_DIR, YARN_LOG_DIR, 追加PATH添加hadoop命令</p>
<ul>
<li>hadoop的九个配置文件</li>
</ul>
<p>都在/hadoop-2.6.0-cdh5.12.1/etc/hadoop目录下</p>
<p>core-site.xml指明对外访问的uri</p>
<p>hdfs-site.xml指明元数据和实际数据放哪里，以及数据备份几份，还有是跳过身份验证</p>
<p>mapred-site.xml指明资源调度框架是yarn</p>
<p>yarn-site.xml指明yarn的aux-services和几个应用的地址</p>
<ul>
<li>配置hadoop用户的免密登录<ul>
<li>每台虚拟机上都创建秘钥，<code>$ ssh-keygen -t rsa</code>，三次回车不加密码</li>
<li>将每个datanode节点上的公钥汇总到namenode1的<code>.ssh/authorized_keys</code>文件中，<code>$ ssh-copy-id -i ~/.ssh/id_rsa.pub namenode1</code></li>
<li>在namenode上将公钥加入授权文件<code>authorized_keys</code>，并设置访问权限600，然后分发到每个datanode节点上<code>$ scp authorized_keys datanode1:.ssh/</code></li>
</ul>
</li>
</ul>
<h2 id="HDFS理论基础和应用开发"><a href="#HDFS理论基础和应用开发" class="headerlink" title="HDFS理论基础和应用开发"></a>HDFS理论基础和应用开发</h2><h3 id="hdfs文件系统特征"><a href="#hdfs文件系统特征" class="headerlink" title="hdfs文件系统特征"></a>hdfs文件系统特征</h3><ul>
<li>存储极大数目的信息（terabytes or petabytes），将数据保存到大量的节点当中。支持很大单个文件。</li>
<li>提供数据的高可靠性，单个或者多个节点不工作，对系统不会造成任何影响，数据仍然可用。</li>
<li>提供对这些信息的快速访问，并提供可扩展的方式。能够通过简单加入更多服务器的方式就能够服务更多的客户端。</li>
<li>HDFS是针对MapReduce设计的，使得数据尽可能根据其本地局部性进行访问与计算。</li>
</ul>
<h3 id="掌握hadoop开发环境搭建"><a href="#掌握hadoop开发环境搭建" class="headerlink" title="掌握hadoop开发环境搭建"></a>掌握hadoop开发环境搭建</h3><ul>
<li>Windows下，下次补充</li>
<li><a href="https://segmentfault.com/a/1190000002676066" target="_blank" rel="noopener">Linux系统下eclipse中配置hadoop开发环境</a></li>
</ul>
<h3 id="掌握hdfs常用基本命令"><a href="#掌握hdfs常用基本命令" class="headerlink" title="掌握hdfs常用基本命令"></a>掌握hdfs常用基本命令</h3><p>hdfs基本命令类似Linux命令格式，有三种<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">hadoop fs -cmd</span><br><span class="line">hadoop dfs -cmd</span><br><span class="line">hdfs dfs -cmd (推荐)</span><br></pre></td></tr></table></figure></p>
<p>基本命令必须掌握的有<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">-ls [-R]</span><br><span class="line">-mkdir [-p]</span><br><span class="line">-put [-f] 本地目录 目标目录</span><br><span class="line">-get 文件路径 本地路径</span><br><span class="line">-cat </span><br><span class="line">-text</span><br><span class="line">-rm [-r]</span><br></pre></td></tr></table></figure></p>
<p>hdfs管理命令<code>hdfs dfsadmin -cmd</code><br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">-printTopology</span><br><span class="line">-report</span><br><span class="line">-safemode [get|enter|leave]</span><br></pre></td></tr></table></figure></p>
<p>最后这个挺重要的，get是查看当前状态（是否进入安全状态），enter是进入安全状态，leave是离开</p>
<ul>
<li>更多内容可以参考<a href="https://blog.csdn.net/lzw2016/article/details/84202239#HDFS_124" target="_blank" rel="noopener">操作hdfs</a></li>
<li><a href="https://hadoop.apache.org/docs/r1.0.4/cn/commands_manual.html" target="_blank" rel="noopener">hadoop中文文档命令手册</a><h3 id="掌握hdfs-API开发"><a href="#掌握hdfs-API开发" class="headerlink" title="掌握hdfs API开发"></a>掌握hdfs API开发</h3></li>
</ul>
<h2 id="了解分布式资源管理及调度框架YARN的优势何在"><a href="#了解分布式资源管理及调度框架YARN的优势何在" class="headerlink" title="了解分布式资源管理及调度框架YARN的优势何在"></a>了解分布式资源管理及调度框架YARN的优势何在</h2><p>因为Hadoop1.0版本中是使用的MapReduce作为资源管理和调度平台的，后来在2.0中就被取代了，但MR这种编程模式仍被保留了</p>
<h2 id="MapReduce编程前的准备"><a href="#MapReduce编程前的准备" class="headerlink" title="MapReduce编程前的准备"></a>MapReduce编程前的准备</h2><ul>
<li>了解hdfs压缩与解压缩概念</li>
<li>了解hdfs如何序列</li>
</ul>
<p>对数据压缩可以优化磁盘使用率，能够提高数据在磁盘和网络中的传输速度</p>
<p>序列化是指将结构化对象转化为字节流以便在网络上<strong>进程间传输</strong>或写到<strong>磁盘上进行永久存储</strong>的过程，相反还有反序列化。hadoop对数据序列化好处不仅是这两点，像格式更加紧凑，易于管理都是</p>
<p>以上说的这些序列化，只要知道就可以了，hadoop通过Writable接口对它们进行了封装，如下</p>
<p>Java基本类型在hadoop上进行Writable封装，如图：<br><img src="/MarkDown_images/大数据/writable.png" alt="1545653077535"><br>常用的无非就是IntWritable、LongWritable、FloatWritable，图中V开头的是定长与不定长的区分，我没用过</p>
<p>其次是Text、NullWritable类</p>
<p>Text是针对utf-8序列的Writable类，可认为是java中的String</p>
<p>NullWritable是hadoop中的空类型，可认为是null，多用来占位使用</p>
<p>而hadoop有提供get和set方法，在java类型和可序列化类型间转换，如</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">IntWritabel one = <span class="keyword">new</span> IntWritable();</span><br><span class="line">one.set(<span class="number">1</span>);<span class="comment">// 由int类型的1转换成可序列化的1</span></span><br><span class="line">one.get();<span class="comment">// 这是反序列化</span></span><br><span class="line"></span><br><span class="line"><span class="comment">// 还有就是NullWritable.get()获取一个值为null的数值</span></span><br></pre></td></tr></table></figure>
<p>自定义Writable类以及WritableComparable类<br>前者是可序列化类，必须实现接口的方法有：<br><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">Writable.write(DataOutput out)</span><br><span class="line">Writable.readFields(DataInput in)</span><br></pre></td></tr></table></figure></p>
<p>后者是可序列化且可比较类，必须实现接口的方法有：<br><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">Writable.write(DataOutput out)</span><br><span class="line">Writable.readFields(DataInput in)</span><br><span class="line">Comparable.compareTo(T o)</span><br></pre></td></tr></table></figure></p>
<h2 id="从wordcount词频统计入手MapReduce编程"><a href="#从wordcount词频统计入手MapReduce编程" class="headerlink" title="从wordcount词频统计入手MapReduce编程"></a>从wordcount词频统计入手MapReduce编程</h2><p>MapReduce编程的核心就是一句话“分而治之，迭代汇总”，只要是分治法可以解决的问题，它都可以做</p>
<p>下面给出wordcount源码，源码来自hadoop自带的词频统计的jar包，稍微改动。如下代码有注释。MapReduce编程都是这么一个模块式编程流程，看懂这个其他模式都一通百通<br><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">WordCount2</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">	<span class="keyword">public</span> <span class="keyword">static</span> <span class="class"><span class="keyword">class</span> <span class="title">TokenizerMapper</span> <span class="keyword">extends</span> <span class="title">Mapper</span>&lt;<span class="title">Object</span>, <span class="title">Text</span>, <span class="title">Text</span>, <span class="title">IntWritable</span>&gt; </span>&#123;		</span><br><span class="line">		<span class="keyword">private</span> <span class="keyword">final</span> <span class="keyword">static</span> IntWritable one = <span class="keyword">new</span> IntWritable(<span class="number">1</span>);</span><br><span class="line">		<span class="keyword">private</span> Text word = <span class="keyword">new</span> Text();</span><br><span class="line"></span><br><span class="line">		<span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">map</span><span class="params">(Object key, Text value, Context context )</span> <span class="keyword">throws</span> IOException, InterruptedException </span>&#123;</span><br><span class="line">	    	StringTokenizer itr = <span class="keyword">new</span> StringTokenizer(value.toString());</span><br><span class="line">	    	<span class="keyword">while</span> (itr.hasMoreTokens()) &#123;</span><br><span class="line">	    		word.set(itr.nextToken());</span><br><span class="line">	    		context.write(word, one);</span><br><span class="line">	    	&#125;</span><br><span class="line">	    &#125;</span><br><span class="line">	&#125;</span><br><span class="line">  </span><br><span class="line">	<span class="keyword">public</span> <span class="keyword">static</span> <span class="class"><span class="keyword">class</span> <span class="title">IntSumReducer</span> <span class="keyword">extends</span> <span class="title">Reducer</span>&lt;<span class="title">Text</span>,<span class="title">IntWritable</span>,<span class="title">Text</span>,<span class="title">IntWritable</span>&gt; </span>&#123;</span><br><span class="line">		<span class="keyword">private</span> IntWritable result = <span class="keyword">new</span> IntWritable();</span><br><span class="line">		</span><br><span class="line">		<span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">reduce</span><span class="params">(Text key, Iterable&lt;IntWritable&gt; values, Context context)</span> <span class="keyword">throws</span> IOException, InterruptedException </span>&#123;</span><br><span class="line">			<span class="keyword">int</span> sum = <span class="number">0</span>;</span><br><span class="line">			<span class="keyword">for</span> (IntWritable val : values) &#123;</span><br><span class="line">				sum += val.get();</span><br><span class="line">			&#125;</span><br><span class="line">			result.set(sum);</span><br><span class="line">			context.write(key, result);</span><br><span class="line">	    &#125;</span><br><span class="line">	&#125;</span><br><span class="line"></span><br><span class="line">	<span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> <span class="keyword">throws</span> Exception </span>&#123;		</span><br><span class="line">		<span class="comment">//1.设置HDFS配置信息</span></span><br><span class="line">		String namenode_ip = <span class="string">"192.168.17.10"</span>;   <span class="comment">//这个是你集群中设置的ip</span></span><br><span class="line">		String hdfs = <span class="string">"hdfs://"</span> + namenode_ip + <span class="string">":9000"</span>;			</span><br><span class="line">		Configuration conf = <span class="keyword">new</span> Configuration();	<span class="comment">//Hadoop配置类</span></span><br><span class="line">		conf.set(<span class="string">"fs.defaultFS"</span>, hdfs);</span><br><span class="line">		conf.set(<span class="string">"mapreduce.app-submission.cross-platform"</span>, <span class="string">"true"</span>);    <span class="comment">//跨平台提交</span></span><br><span class="line">		<span class="comment">//集群交叉提交</span></span><br><span class="line"><span class="comment">/*		conf.set("hadoop.job.user", "hadoop");</span></span><br><span class="line"><span class="comment">		conf.set("mapreduce.framework.name", "yarn");</span></span><br><span class="line"><span class="comment">		conf.set("mapreduce.jobtracker.address", namenode_ip + ":9001");</span></span><br><span class="line"><span class="comment">		conf.set("yarn.resourcemanager.hostname", namenode_ip);	</span></span><br><span class="line"><span class="comment">		conf.set("yarn.resourcemanager.resource-tracker.address", namenode_ip + ":8031");</span></span><br><span class="line"><span class="comment">		conf.set("yarn.resourcemtanager.address", namenode_ip + ":8032");</span></span><br><span class="line"><span class="comment">		conf.set("yarn.resourcemanager.admin.address", namenode_ip + ":8033");</span></span><br><span class="line"><span class="comment">		conf.set("yarn.resourcemanager.scheduler.address", namenode_ip + ":8034");</span></span><br><span class="line"><span class="comment">		conf.set("mapreduce.jobhistory.address", namenode_ip + ":10020"); */</span></span><br><span class="line">		</span><br><span class="line">		<span class="comment">//2.设置MapReduce作业配置信息</span></span><br><span class="line">		String jobName = <span class="string">"WordCount2"</span>;					<span class="comment">//定义作业名称</span></span><br><span class="line">		Job job = Job.getInstance(conf, jobName);</span><br><span class="line">		job.setJarByClass(WordCount2.class);			<span class="comment">//指定作业类</span></span><br><span class="line">		job.setJar(<span class="string">"export\\WordCount2.jar"</span>);			<span class="comment">//指定本地jar包</span></span><br><span class="line">		job.setMapperClass(TokenizerMapper.class);      <span class="comment">//指定Mapper类</span></span><br><span class="line">		job.setCombinerClass(IntSumReducer.class);		<span class="comment">//指定Combiner类</span></span><br><span class="line">		job.setReducerClass(IntSumReducer.class);       <span class="comment">//指定Reducer类</span></span><br><span class="line">		job.setOutputKeyClass(Text.class);              <span class="comment">//指定输出Key的类型</span></span><br><span class="line">		job.setOutputValueClass(IntWritable.class);     <span class="comment">//指定输出Value类型</span></span><br><span class="line">		</span><br><span class="line">		<span class="comment">//3.设置作业输入和输出路径</span></span><br><span class="line">		String dataDir = <span class="string">"/expr/wordcount/data"</span>;		<span class="comment">//实验数据目录	</span></span><br><span class="line">		String outputDir = <span class="string">"/expr/wordcount/output"</span>;	<span class="comment">//实验输出目录</span></span><br><span class="line">		Path inPath = <span class="keyword">new</span> Path(hdfs + dataDir);</span><br><span class="line">		Path outPath = <span class="keyword">new</span> Path(hdfs + outputDir);</span><br><span class="line">		FileInputFormat.addInputPath(job, inPath);      <span class="comment">//文件输入目录</span></span><br><span class="line">		FileOutputFormat.setOutputPath(job, outPath);   <span class="comment">//文件输出目录</span></span><br><span class="line">		<span class="comment">//如果输出目录已存在则删除</span></span><br><span class="line">		<span class="comment">//必须删，hadoop的一个bug，不删会报错</span></span><br><span class="line">		FileSystem fs = FileSystem.get(conf);</span><br><span class="line">		<span class="keyword">if</span>(fs.exists(outPath)) &#123;</span><br><span class="line">			fs.delete(outPath, <span class="keyword">true</span>);</span><br><span class="line">		&#125;</span><br><span class="line">		</span><br><span class="line">		<span class="comment">//4.运行作业</span></span><br><span class="line">		System.out.println(<span class="string">"Job: "</span> + jobName + <span class="string">" is running..."</span>);</span><br><span class="line">		<span class="keyword">if</span>(job.waitForCompletion(<span class="keyword">true</span>)) &#123;</span><br><span class="line">			System.out.println(<span class="string">"success!"</span>);</span><br><span class="line">			System.exit(<span class="number">0</span>);</span><br><span class="line">		&#125; <span class="keyword">else</span> &#123;</span><br><span class="line">			System.out.println(<span class="string">"failed!"</span>);</span><br><span class="line">			System.exit(<span class="number">1</span>);</span><br><span class="line">		&#125;</span><br><span class="line">	&#125;</span><br><span class="line"></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>
<ul>
<li>点击这里下载运行：<a href="https://github.com/josonle/MapReduce-Demo/tree/master/src/main/java/mapReduceTest/wordCount" target="_blank" rel="noopener">wordCount源码文件</a></li>
<li>启动hdfs、yarn【<code>start-dfs.sh</code>、<code>start-yarn.sh</code>，或者<code>start-all.sh</code>】</li>
<li>可启动jobhistory服务 <code>mr-jobhistory-daemon.sh start  historyserver</code></li>
<li>确保hdfs上<code>/expr/wordcount/data</code>目录下有数据，没有的话<code>hdfs dfs -put xxx /expr/wordcount/data</code>上传即可</li>
<li>eclipse下运行即可（hadoop插件会自动上传所需的编译文件以便运行），或者上传打好的jar包到linux上，通过<code>hadoop jar</code>来运行</li>
<li>查看运行结果 <code>hdfs  dfs  -cat /expr/wordcount/output/part-r-00000</code>(通过hadoop插件也可以看到)</li>
</ul>
<p>MapReduce程序运行在一个分布式集群中，合理利用集群中的资源，发挥出分布式集群中各个节点本身的处理能力。MapReduce框架使分布式计算中网络处理、协调不同节点的资源调配、任务协同变得简单透明</p>
<p>MapReduce分为Map和Reduce两个阶段，是在HDFS存储数据的基础上，将一个较大的计算任务分解成若干个小任务，每个小任务都由一个Map程序来计算（尽量在数据所在的节点上完成），再将每个Map的计算结果由一个或多个Reduce程序合并计算得到最终结果 </p>
<p><a href="https://imgchr.com/i/FcpYGT" target="_blank" rel="noopener"><img src="https://s1.ax1x.com/2018/12/24/FcpYGT.png" alt="FcpYGT.png"></a></p>
<p><a href="https://imgchr.com/i/Fcp8I0" target="_blank" rel="noopener"><img src="https://s1.ax1x.com/2018/12/24/Fcp8I0.jpg" alt="Fcp8I0.jpg"></a><br><a href="https://imgchr.com/i/FcptRU" target="_blank" rel="noopener"><img src="https://s1.ax1x.com/2018/12/24/FcptRU.png" alt="FcptRU.png"></a></p>
<h2 id="MapReduce过程详解【含Shuffle过程】"><a href="#MapReduce过程详解【含Shuffle过程】" class="headerlink" title="MapReduce过程详解【含Shuffle过程】"></a>MapReduce过程详解【含Shuffle过程】</h2><p>这一步是为了充分认识了解MR的整个过程，能够更好地了解该如何设计MR程序以解决问题</p>
<h3 id="Mapper类源码阅读"><a href="#Mapper类源码阅读" class="headerlink" title="Mapper类源码阅读"></a>Mapper类源码阅读</h3><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">protected</span> <span class="keyword">void</span> <span class="title">setup</span><span class="params">(Context context)</span> <span class="keyword">throws</span> IOException, InterruptedException </span>&#123;</span><br><span class="line"><span class="comment">// NOTHING</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">protected</span> <span class="keyword">void</span> <span class="title">map</span><span class="params">(KEYIN key, VALUEIN value, </span></span></span><br><span class="line"><span class="function"><span class="params">                     Context context)</span> <span class="keyword">throws</span> IOException, InterruptedException </span>&#123;</span><br><span class="line">context.write((KEYOUT) key, (VALUEOUT) value);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">protected</span> <span class="keyword">void</span> <span class="title">cleanup</span><span class="params">(Context context)</span> <span class="keyword">throws</span> IOException, InterruptedException </span>&#123;</span><br><span class="line"><span class="comment">// NOTHING</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">run</span><span class="params">(Context context)</span> <span class="keyword">throws</span> IOException, InterruptedException </span>&#123;</span><br><span class="line">    setup(context);</span><br><span class="line">    <span class="keyword">while</span> (context.nextKeyValue()) &#123;</span><br><span class="line">      map(context.getCurrentKey(), context.getCurrentValue(), context);</span><br><span class="line">    &#125;</span><br><span class="line">    cleanup(context);</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h3 id="Reducer类源码阅读"><a href="#Reducer类源码阅读" class="headerlink" title="Reducer类源码阅读"></a>Reducer类源码阅读</h3><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment">   * Called once at the start of the task.</span></span><br><span class="line"><span class="comment">   */</span></span><br><span class="line">  <span class="function"><span class="keyword">protected</span> <span class="keyword">void</span> <span class="title">setup</span><span class="params">(Context context</span></span></span><br><span class="line"><span class="function"><span class="params">                       )</span> <span class="keyword">throws</span> IOException, InterruptedException </span>&#123;</span><br><span class="line">    <span class="comment">// NOTHING</span></span><br><span class="line">  &#125;</span><br><span class="line">  </span><br><span class="line"> <span class="comment">/**</span></span><br><span class="line"><span class="comment">   * This method is called once for each key. Most applications will define</span></span><br><span class="line"><span class="comment">   * their reduce class by overriding this method. The default implementation</span></span><br><span class="line"><span class="comment">   * is an identity function.</span></span><br><span class="line"><span class="comment">   */</span></span><br><span class="line">  <span class="meta">@SuppressWarnings</span>(<span class="string">"unchecked"</span>)</span><br><span class="line">  <span class="function"><span class="keyword">protected</span> <span class="keyword">void</span> <span class="title">reduce</span><span class="params">(KEYIN key, Iterable&lt;VALUEIN&gt; values, Context context</span></span></span><br><span class="line"><span class="function"><span class="params">                        )</span> <span class="keyword">throws</span> IOException, InterruptedException </span>&#123;</span><br><span class="line">    <span class="keyword">for</span>(VALUEIN value: values) &#123;</span><br><span class="line">      context.write((KEYOUT) key, (VALUEOUT) value);</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">  </span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment">   * Called once at the end of the task.</span></span><br><span class="line"><span class="comment">   */</span></span><br><span class="line">  <span class="function"><span class="keyword">protected</span> <span class="keyword">void</span> <span class="title">cleanup</span><span class="params">(Context context</span></span></span><br><span class="line"><span class="function"><span class="params">                         )</span> <span class="keyword">throws</span> IOException, InterruptedException </span>&#123;</span><br><span class="line">    <span class="comment">// NOTHING</span></span><br><span class="line">  &#125;</span><br><span class="line">  </span><br><span class="line"><span class="comment">/*</span></span><br><span class="line"><span class="comment">   * control how the reduce task works.</span></span><br><span class="line"><span class="comment">   */</span></span><br><span class="line">  <span class="meta">@SuppressWarnings</span>(<span class="string">"unchecked"</span>)</span><br><span class="line">  <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">run</span><span class="params">(Context context)</span> <span class="keyword">throws</span> IOException, InterruptedException </span>&#123;</span><br><span class="line">    setup(context);</span><br><span class="line">    <span class="keyword">while</span> (context.nextKey()) &#123;</span><br><span class="line">      reduce(context.getCurrentKey(), context.getValues(), context);</span><br><span class="line">      <span class="comment">// If a back up store is used, reset it</span></span><br><span class="line">      ((ReduceContext.ValueIterator)</span><br><span class="line">          (context.getValues().iterator())).resetBackupStore();</span><br><span class="line">    &#125;</span><br><span class="line">    cleanup(context);</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>这部分内容太多了，不在这里写了，可以看我这几篇博客<a href="https://blog.csdn.net/lzw2016/article/details/84779254" target="_blank" rel="noopener">【MapReduce详解及源码解析（一）】——分片输入、Mapper及Map端Shuffle过程</a>，<a href="https://blog.csdn.net/lzw2016/article/details/84674096" target="_blank" rel="noopener">MapReduce:详解Shuffle过程</a></p>
<h2 id="终极杀招-MapReduce系统编程实战操练"><a href="#终极杀招-MapReduce系统编程实战操练" class="headerlink" title="终极杀招 MapReduce系统编程实战操练"></a>终极杀招 MapReduce系统编程实战操练</h2><p><a href="https://blog.csdn.net/lzw2016/article/details/84928495" target="_blank" rel="noopener">大数据之Hadoop学习——动手实战学习MapReduce编程实例</a></p>
<p>目录如下<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line">- MapReduce编程实例</span><br><span class="line">  - 1.自定义对象序列化</span><br><span class="line">  - 2.数据去重</span><br><span class="line">  - 3.数据排序、二次排序 </span><br><span class="line">  - 4.自定义分区</span><br><span class="line">  - 5.计算出每组订单中金额最大的记录</span><br><span class="line">  - 多文件输入输出、及不同输入输出格式化类型</span><br><span class="line">    - 6.合并多个小文件</span><br><span class="line">    - 7.分组输出到多个文件</span><br><span class="line">  - 8.join操作</span><br><span class="line">  - 9.计算出用户间的共同好友</span><br><span class="line">- MapReduce理论基础</span><br><span class="line">- Hadoop、Spark学习路线及资源收纳</span><br><span class="line">- MapReduce实战系统学习流程</span><br><span class="line">  - 词频统计</span><br><span class="line">  - 数据去重</span><br><span class="line">  - 数据排序</span><br><span class="line">  - 求平均值、中位数、标准差、最大/小值、计数</span><br><span class="line">  - 分组、分区</span><br><span class="line">  - 数据输入输出格式化</span><br><span class="line">  - 多文件输入、输出</span><br><span class="line">  - 多文件输入、输出</span><br><span class="line">  - 单表关联</span><br><span class="line">  - 多表关联</span><br><span class="line">  - 倒排索引</span><br><span class="line">  - TopN</span><br><span class="line">  - 作业链</span><br><span class="line">- 项目</span><br><span class="line">  - Web日志KPI指标分析</span><br><span class="line">  - PeopleRank算法实现</span><br><span class="line">  - 推荐系统——基于物品的协同过滤算法实现</span><br></pre></td></tr></table></figure></p>
<h2 id="hadoop资源分享"><a href="#hadoop资源分享" class="headerlink" title="hadoop资源分享"></a>hadoop资源分享</h2><p><a href="https://blog.csdn.net/lzw2016/article/details/84202278" target="_blank" rel="noopener">Hadoop及Spark学习路线及资源收纳</a></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line">一、学习路线图</span><br><span class="line">Hadoop家族学习路线图 开篇必读</span><br><span class="line">Hive学习路线图</span><br><span class="line">Mahout学习路线图</span><br><span class="line"></span><br><span class="line">二、编程实践</span><br><span class="line">Hadoop历史版本安装</span><br><span class="line">用Maven构建Hadoop项目</span><br><span class="line">Hadoop编程调用HDFS</span><br><span class="line">用Maven构建Mahout项目</span><br><span class="line">Mahout推荐算法API详解</span><br><span class="line">用MapReduce实现矩阵乘法</span><br><span class="line">从源代码剖析Mahout推荐引擎</span><br><span class="line">Mahout分步式程序开发 基于物品的协同过滤ItemCF</span><br><span class="line">Mahout分步式程序开发 聚类Kmeans</span><br><span class="line">PageRank算法并行实现</span><br><span class="line"></span><br><span class="line">三、案例分析</span><br><span class="line">海量Web日志分析 用Hadoop提取KPI统计指标</span><br><span class="line">用Hadoop构建电影推荐系统</span><br><span class="line">用Mahout构建职位推荐引擎</span><br><span class="line">Mahout构建图书推荐系统</span><br><span class="line">PeopleRank从社交网络中发现个体价值</span><br><span class="line">--------------------- </span><br><span class="line">作者：lzw2016 </span><br><span class="line">来源：CSDN </span><br><span class="line">原文：https://blog.csdn.net/lzw2016/article/details/84202278 </span><br><span class="line">版权声明：本文为博主原创文章，转载请附上博文链接！</span><br></pre></td></tr></table></figure>
      
    </div>
    
    
    

    

    
      <div>
        <div style="padding: 10px 0; margin: 20px auto; width: 90%; text-align: center;">
  <div>觉得有帮助的话，不妨加个鸡腿，O(∩_∩)O哈哈~</div>
  <button id="rewardButton" disable="enable" onclick="var qr = document.getElementById('QR'); if (qr.style.display === 'none') {qr.style.display='block';} else {qr.style.display='none'}">
    <span>打赏</span>
  </button>
  <div id="QR" style="display: none;">

    
      <div id="wechat" style="display: inline-block">
        <img id="wechat_qr" src="/images/weChatPay.jpg" alt="Joson lee 微信支付"/>
        <p>微信支付</p>
      </div>
    

    
      <div id="alipay" style="display: inline-block">
        <img id="alipay_qr" src="/images/aliPay.jpg" alt="Joson lee 支付宝"/>
        <p>支付宝</p>
      </div>
    

    

  </div>
</div>

      </div>
    

    

    <footer class="post-footer">
      
        <div class="post-tags">
          
            <a href="/tags/Hadoop/" rel="tag"># Hadoop</a>
          
        </div>
      

      
      
      

      
        <div class="post-nav">
          <div class="post-nav-next post-nav-item">
            
              <a href="/blog/2018-12-20-MapReduce算法中如何使用setup-和cleanup-进行优化.html/" rel="next" title="MapReduce算法中如何使用setup()和cleanup()进行优化">
                <i class="fa fa-chevron-left"></i> MapReduce算法中如何使用setup()和cleanup()进行优化
              </a>
            
          </div>

          <span class="post-nav-divider"></span>

          <div class="post-nav-prev post-nav-item">
            
              <a href="/blog/2019-01-18-《软件工程》复习总结.html/" rel="prev" title="《软件工程》复习总结">
                《软件工程》复习总结 <i class="fa fa-chevron-right"></i>
              </a>
            
          </div>
        </div>
      

      
      
    </footer>
  </div>
  
  
  
  </article>



    <div class="post-spread">
      
    </div>
  </div>


          </div>
          


          

  
    <div id="gitalk-container"></div>
  



        </div>
        
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    
    <div class="sidebar-inner">

      

      
        <ul class="sidebar-nav motion-element">
          <li class="sidebar-nav-toc sidebar-nav-active" data-target="post-toc-wrap">
            文章目录
          </li>
          <li class="sidebar-nav-overview" data-target="site-overview-wrap">
            站点概览
          </li>
        </ul>
      

      <section class="site-overview-wrap sidebar-panel">
        <div class="site-overview">
          <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
            
              <img class="site-author-image" itemprop="image"
                src="/images/logo.png"
                alt="Joson lee" />
            
              <p class="site-author-name" itemprop="name">Joson lee</p>
              <p class="site-description motion-element" itemprop="description">Python数据分析、机器学习、Django、java学习</p>
          </div>

          <nav class="site-state motion-element">

            
              <div class="site-state-item site-state-posts">
              
                <a href="/archives/">
              
                  <span class="site-state-item-count">26</span>
                  <span class="site-state-item-name">日志</span>
                </a>
              </div>
            

            
              
              
              <div class="site-state-item site-state-categories">
                <a href="/categories/index.html">
                  <span class="site-state-item-count">9</span>
                  <span class="site-state-item-name">分类</span>
                </a>
              </div>
            

            
              
              
              <div class="site-state-item site-state-tags">
                <a href="/tags/index.html">
                  <span class="site-state-item-count">12</span>
                  <span class="site-state-item-name">标签</span>
                </a>
              </div>
            

          </nav>

          

          
            <div class="links-of-author motion-element">
                
                  <span class="links-of-author-item">
                    <a href="https://github.com/josonle" target="_blank" title="GitHub">
                      
                        <i class="fa fa-fw fa-github"></i>GitHub</a>
                  </span>
                
                  <span class="links-of-author-item">
                    <a href="http://blog.csdn.net/lzw2016" target="_blank" title="CSDN">
                      
                        <i class="fa fa-fw fa-csdn"></i>CSDN</a>
                  </span>
                
                  <span class="links-of-author-item">
                    <a href="mailto:3092312003@qq.com" target="_blank" title="E-Mail">
                      
                        <i class="fa fa-fw fa-envelope"></i>E-Mail</a>
                  </span>
                
            </div>
          

          
          

          
          

          

        </div>
      </section>

      
      <!--noindex-->
        <section class="post-toc-wrap motion-element sidebar-panel sidebar-panel-active">
          <div class="post-toc">

            
              
            

            
              <div class="post-toc-content"><ol class="nav"><li class="nav-item nav-level-2"><a class="nav-link" href="#Hadoop概述"><span class="nav-number">1.</span> <span class="nav-text">Hadoop概述</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#Google三驾马车"><span class="nav-number">1.1.</span> <span class="nav-text">Google三驾马车</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Hadoop生态系统"><span class="nav-number">2.</span> <span class="nav-text">Hadoop生态系统</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Hadoop先修准备Linux-shell学习"><span class="nav-number">3.</span> <span class="nav-text">Hadoop先修准备Linux shell学习</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#掌握Hadoop集群搭建"><span class="nav-number">4.</span> <span class="nav-text">掌握Hadoop集群搭建</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#有几点需要注意"><span class="nav-number">4.1.</span> <span class="nav-text">有几点需要注意</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#HDFS理论基础和应用开发"><span class="nav-number">5.</span> <span class="nav-text">HDFS理论基础和应用开发</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#hdfs文件系统特征"><span class="nav-number">5.1.</span> <span class="nav-text">hdfs文件系统特征</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#掌握hadoop开发环境搭建"><span class="nav-number">5.2.</span> <span class="nav-text">掌握hadoop开发环境搭建</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#掌握hdfs常用基本命令"><span class="nav-number">5.3.</span> <span class="nav-text">掌握hdfs常用基本命令</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#掌握hdfs-API开发"><span class="nav-number">5.4.</span> <span class="nav-text">掌握hdfs API开发</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#了解分布式资源管理及调度框架YARN的优势何在"><span class="nav-number">6.</span> <span class="nav-text">了解分布式资源管理及调度框架YARN的优势何在</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#MapReduce编程前的准备"><span class="nav-number">7.</span> <span class="nav-text">MapReduce编程前的准备</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#从wordcount词频统计入手MapReduce编程"><span class="nav-number">8.</span> <span class="nav-text">从wordcount词频统计入手MapReduce编程</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#MapReduce过程详解【含Shuffle过程】"><span class="nav-number">9.</span> <span class="nav-text">MapReduce过程详解【含Shuffle过程】</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#Mapper类源码阅读"><span class="nav-number">9.1.</span> <span class="nav-text">Mapper类源码阅读</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Reducer类源码阅读"><span class="nav-number">9.2.</span> <span class="nav-text">Reducer类源码阅读</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#终极杀招-MapReduce系统编程实战操练"><span class="nav-number">10.</span> <span class="nav-text">终极杀招 MapReduce系统编程实战操练</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#hadoop资源分享"><span class="nav-number">11.</span> <span class="nav-text">hadoop资源分享</span></a></li></ol></div>
            

          </div>
        </section>
      <!--/noindex-->
      

      

    </div>
  </aside>


        
      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <div class="copyright">&copy; <span itemprop="copyrightYear">2019</span>
  <span class="with-love">
    <i class="fa fa-user"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">Joson lee</span>

  
    <span class="post-meta-divider">|</span>
    <span class="post-meta-item-icon">
      <i class="fa fa-area-chart"></i>
    </span>
    
      <span class="post-meta-item-text">Site words total count&#58;</span>
    
    <span title="Site words total count"></span>
  
</div>


  <div class="powered-by">由 <a class="theme-link" target="_blank" href="https://hexo.io">Hexo</a> 强力驱动</div>



  <span class="post-meta-divider">|</span>



  <div class="theme-info">主题 &mdash; <a class="theme-link" target="_blank" href="https://github.com/iissnan/hexo-theme-next">NexT.Gemini</a> v5.1.4</div>




        
<div class="busuanzi-count">
  <script async src="https://busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>

  
    <span class="site-uv">
      <i class="fa fa-user"></i> 访问人数
      <span class="busuanzi-value" id="busuanzi_value_site_uv"></span>
      人
    </span>
  

  
    <span class="site-pv">
      <i class="fa fa-eye"></i> 总访问量
      <span class="busuanzi-value" id="busuanzi_value_site_pv"></span>
      次
    </span>
  
</div>








        
      </div>
    </footer>

    
      <div class="back-to-top">
        <i class="fa fa-arrow-up"></i>
        
      </div>
    

    

  </div>

  

<script type="text/javascript">
  if (Object.prototype.toString.call(window.Promise) !== '[object Function]') {
    window.Promise = null;
  }
</script>









  












  
  
    <script type="text/javascript" src="/lib/jquery/index.js?v=2.1.3"></script>
  

  
  
    <script type="text/javascript" src="/lib/fastclick/lib/fastclick.min.js?v=1.0.6"></script>
  

  
  
    <script type="text/javascript" src="/lib/jquery_lazyload/jquery.lazyload.js?v=1.9.7"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.ui.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/fancybox/source/jquery.fancybox.pack.js?v=2.1.5"></script>
  


  


  <script type="text/javascript" src="/js/src/utils.js?v=5.1.4"></script>

  <script type="text/javascript" src="/js/src/motion.js?v=5.1.4"></script>



  
  


  <script type="text/javascript" src="/js/src/affix.js?v=5.1.4"></script>

  <script type="text/javascript" src="/js/src/schemes/pisces.js?v=5.1.4"></script>



  
  <script type="text/javascript" src="/js/src/scrollspy.js?v=5.1.4"></script>
<script type="text/javascript" src="/js/src/post-details.js?v=5.1.4"></script>



  


  <script type="text/javascript" src="/js/src/bootstrap.js?v=5.1.4"></script>



  


  




	





  





  










  <link rel="stylesheet" href="https://unpkg.com/gitalk/dist/gitalk.css">
  <script src="https://unpkg.com/gitalk/dist/gitalk.min.js"></script>
  <script src="/js/src/md5.min.js"></script>
   <script type="text/javascript">
        var gitalk = new Gitalk({
          clientID: 'a94818509a8f36c0a222',
          clientSecret: '4d6bcd339e8df5f3e1f9e653afa2a5b9a1023f0f',
          repo: 'josonle.github.io',
          owner: 'josonle',
          admin: ['josonle'],
          id: md5(location.pathname),
          distractionFreeMode: 'true'
        })
        gitalk.render('gitalk-container')
    </script>




  





  

  

  
<script>
(function(){
    var bp = document.createElement('script');
    var curProtocol = window.location.protocol.split(':')[0];
    if (curProtocol === 'https') {
        bp.src = 'https://zz.bdstatic.com/linksubmit/push.js';        
    }
    else {
        bp.src = 'http://push.zhanzhang.baidu.com/push.js';
    }
    var s = document.getElementsByTagName("script")[0];
    s.parentNode.insertBefore(bp, s);
})();
</script>


  
  

  

  

  

</body>
</html>
